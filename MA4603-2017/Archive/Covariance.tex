
			\subsection{Covariance}
			Covariances are useful to find the variances for sums of random variables.
			A general result is that for constant a, b
			
			\[var(aX + bY ) = a^2 var(X) + 2ab cov(X, Y ) + b^2 var(Y ).\]
			
			
			%----------------------------------------------------------------------------------%
			
			\subsection{Covariance}
			\begin{itemize}
				\item Suppose we know, for two random variables $X$ and $Y$, that $\mbox{ Var}(X) =0.7$, $\mbox{ Var}(Y) = 0.9$ and $\mbox{ Cov}(X,Y) = 1.2$
				\item Use the formula on the previous slide to compute $\mbox{ Var}(2X + 3Y )$
				
			\end{itemize}
			
			\[\mbox{ Var}(2X + 3Y ) = [2^2 \mbox{ Var} (X)] + [2\times 2\times 3 \mbox{ Cov}(X, Y )] + [3^2 \mbox{ Var}(Y )].\] \bigskip
			\[\mbox{ Var}(2X + 3Y ) = [2^2 \times 0.7] + [2\times 2\times 3 \times 1.4] +[ 3^2 \times 0.9].\] \bigskip
			\[\mbox{ Var}(2X + 3Y ) = [2.8] + [14.4 ]+ [8.1]= { 25.3}.\]
			
			%------------------------------------------------------------%
			

			\subsection{Independence}
			
			We say that discrete random variables X and Y are independent6 if for all pairs
			of values (x, y)
			\[ P[X = x, Y = y] = P[X = x] \times P[Y = y].\]
			(Notice that this is a precise
			technical definition for a concept used much more
			imprecisely in ordinary speech.)
			
			
			
			%------------------------------------------------------------%
			
			
			\subsection{Covariance}
			The covariance, written  $cov(X, Y )$ (or $sigma_{XY}$), of two jointly distributed random
			variables (X, Y ) is defined by
			
			\[ cov(X, Y ) = E[(X - E(X))(Y - E(Y ))].\]
			
			That covariance is positive when X and Y have a direct association and negative
			when they are inversely related.
			
			Necessarily $cov(X, Y ) = cov(Y,X)$.
			
			If X and Y are independent, then $cov(X, Y ) = 0$, for
			
			\[
			cov(X, Y ) = E[(X - E(X))(Y - E(Y ))]
			= E[X - E(X)]E[Y - E(Y )]= 0 \times 0 = 0.
			\]
			
		


\subsection{Covariance} The covariance of any two random
variables X and Y , denoted by $\mbox{Cov}(X,Y)$, is defined by
$\mbox{Cov}(X,Y) = E[XY] - E[X]E[Y]$.


\subsubsection{Properties of Covariance}
For any random variables X, Y,Z and constant c,
\begin{enumerate}\item \mbox{Cov}(X,X) = \mbox{Var}(X), \item
\mbox{Cov}(X,Y) = \mbox{Cov}(Y,X), \item \mbox{Cov}(kX,Y) =
\mbox{k}Cov(X, Y ), \item \mbox{Cov}(X, Y +Z) = \mbox{Cov}(X,Y) +
\mbox{Cov}(X,Z).\end{enumerate}

