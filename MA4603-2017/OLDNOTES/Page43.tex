
Types of Error

There are two ways in which the results of a hypothesis test may be wrong

Type I Error where the null hypothesis is reject in favour of the alternative hypothesis when the null hypothesis is in fact true.

Type II Error: where the null hypothesis is not rejected and is in fact false.

%---------------------------------%


The probability of a Type I error is called $\alpha$, the significance level.

The significance level must be specified before doing a test. It is controlled by the experimenter.
The most commonly used significance level is $5\%$.


Significance Level defines the probability that is considered two low to warrange support of the hypothesis being tested.

Type II Error is called $\beta$ and depends on the size of the effect one is interested in, and the sample size.

We wanrt to both types of error samll by the are not independent.

%------------------------%
The power of a test is $1- \beta$ and is the probability that we reject the null hypothesis when the alternative hypothesis is true.
A well designed experiment should have relatively high power.

Summary of the procedure of hypothesis testing
There will always be two hypotheses A and B. The statistician will identify numerical values associated
with these hypotheses and will focus on the difference between them,

This difference enables the test statistic to be calculared.

If this is higher than a predetermined critical value, it is highly improbably that hypothesis A is correct.

In that case, we reject A in favour of hypothesis B.

%----------------------------------------------%


